{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASH\\AppData\\Local\\Temp\\ipykernel_6656\\350078299.py:8: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('dataset.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C1       0.82      0.78      0.80      5615\n",
      "          C2       0.90      0.92      0.91     11545\n",
      "\n",
      "    accuracy                           0.87     17160\n",
      "   macro avg       0.86      0.85      0.85     17160\n",
      "weighted avg       0.87      0.87      0.87     17160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Select relevant columns for prediction\n",
    "features = ['Data_Value_Type', 'Data_Value_Alt', 'Break_out', 'GeoLocation']\n",
    "target = 'CategoryID'  # Assuming CategoryID represents the cardiovascular disease presence\n",
    "\n",
    "# Preprocess the data\n",
    "le = LabelEncoder()\n",
    "data['Data_Value_Type'] = le.fit_transform(data['Data_Value_Type'])\n",
    "data['Break_out'] = le.fit_transform(data['Break_out'])\n",
    "data['GeoLocation'] = le.fit_transform(data['GeoLocation'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "column_name ='Confidence_Limit_Low'\n",
    "\n",
    "data[column_name] = pd.to_numeric(data[column_name], errors='coerce').fillna(0)\n",
    "\n",
    "# Print the modified column\n",
    "print(data[column_name])\n",
    "output_file = 'modified_column.txt'\n",
    "data[column_name].to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Replace strings in Confidence_Limit_Low and Confidence_Limit_High with 0\n",
    "data['Confidence_Limit_Low'] = pd.to_numeric(data['Confidence_Limit_Low'], errors='coerce').fillna(0)\n",
    "data['Confidence_Limit_High'] = pd.to_numeric(data['Confidence_Limit_High'], errors='coerce').fillna(0)\n",
    "output_file = 'modified_column.txt'\n",
    "data['Confidence_Limit_Low'].to_csv(output_file, index=False)\n",
    "output_file2 = 'modified_column2.txt'\n",
    "data['Confidence_Limit_High'].to_csv(output_file2, index=False)\n",
    "\n",
    "# Select relevant columns for prediction\n",
    "features = ['Data_Value_Alt', 'Confidence_Limit_Low', 'Confidence_Limit_High']\n",
    "target_range = [9, 11]  # Specify the range for Data_Value_Alt\n",
    "# target_unstable = [11,]  # Specify the value representing unstable estimates\n",
    "\n",
    "# # Preprocess the data\n",
    "# data['Data_Value_Alt'] = data['Data_Value_Alt'].fillna(target_unstable)\n",
    "# data['Data_Value_Alt'] = pd.to_numeric(data['Data_Value_Alt'], errors='coerce')\n",
    "\n",
    "# Separate the dataset into two subsets based on the target value\n",
    "data_within_range = data[(data['Data_Value_Alt'] >= target_range[0]) & (data['Data_Value_Alt'] <= target_range[1])]\n",
    "data_unstable = data[(data['Data_Value_Alt'] <= target_range[0]) & (data['Data_Value_Alt'] >= target_range[1])]\n",
    "print((data['Data_Value_Alt'] <= target_range[0]))\n",
    "\n",
    "\n",
    "# Prepare the data for prediction\n",
    "X_range = data_within_range[['Confidence_Limit_Low', 'Confidence_Limit_High']]\n",
    "y_range = data_within_range['Data_Value_Alt']\n",
    "X_unstable = data_unstable[['Confidence_Limit_Low', 'Confidence_Limit_High']]\n",
    "\n",
    "print(X_unstable)\n",
    "# Split the data into training and testing sets for range prediction\n",
    "X_train_range, X_test_range, y_train_range, y_test_range = train_test_split(X_range, y_range, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model for range prediction\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_range, y_train_range)\n",
    "\n",
    "# Make predictions on the test set for range prediction\n",
    "y_pred_range = regressor.predict(X_test_range)\n",
    "\n",
    "# Split the data into training and testing sets for unstable prediction\n",
    "X_train_unstable, X_test_unstable, y_train_unstable, y_test_unstable = train_test_split(X_unstable, data_unstable['Data_Value_Alt'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier for unstable prediction\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_unstable, y_train_unstable)\n",
    "\n",
    "# Make predictions on the test set for unstable prediction\n",
    "y_pred_unstable = classifier.predict(X_test_unstable)\n",
    "\n",
    "# Print the number of patients within the range\n",
    "print(\"Patients within the range:\", len(data_within_range))\n",
    "\n",
    "# Print the number of unstable estimates\n",
    "print(\"Unstable estimates:\", len(data_unstable))\n",
    "\n",
    "# Classification report for unstable predictions\n",
    "print(classification_report(y_test_unstable, y_pred_unstable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Replace strings in Confidence_Limit_Low and Confidence_Limit_High with 0\n",
    "data['Confidence_Limit_Low'] = pd.to_numeric(data['Confidence_Limit_Low'], errors='coerce').fillna(0)\n",
    "data['Confidence_Limit_High'] = pd.to_numeric(data['Confidence_Limit_High'], errors='coerce').fillna(0)\n",
    "\n",
    "# Select relevant columns for prediction\n",
    "features = ['Data_Value_Alt', 'Confidence_Limit_Low', 'Confidence_Limit_High']\n",
    "target_range = [7.5, 8.5]  # Specify the range for Data_Value_Alt\n",
    "target_unstable = '~'  # Specify the value representing unstable estimates\n",
    "\n",
    "# Preprocess the data\n",
    "data['Data_Value_Alt'] = data['Data_Value_Alt'].fillna(target_unstable)\n",
    "data['Data_Value_Alt'] = pd.to_numeric(data['Data_Value_Alt'], errors='coerce')\n",
    "\n",
    "# Separate the dataset into two subsets based on the target value\n",
    "data_within_range = data[(data['Data_Value_Alt'] >= target_range[0]) & (data['Data_Value_Alt'] <= target_range[1])]\n",
    "data_unstable = data[data['Data_Value_Alt'] == target_unstable]\n",
    "\n",
    "# Prepare the data for prediction\n",
    "X_range = data_within_range[['Confidence_Limit_Low', 'Confidence_Limit_High']]\n",
    "y_range = data_within_range['Data_Value_Alt']\n",
    "X_unstable = data_unstable[['Confidence_Limit_Low', 'Confidence_Limit_High']]\n",
    "\n",
    "# Check if there are enough samples for range prediction\n",
    "if len(data_within_range) < 2:\n",
    "    print(\"Not enough samples for range prediction.\")\n",
    "    exit()\n",
    "\n",
    "# Check if there are enough samples for unstable prediction\n",
    "if len(data_unstable) < 2:\n",
    "    print(\"Not enough samples for unstable prediction.\")\n",
    "    exit()\n",
    "\n",
    "# Split the data into training and testing sets for range prediction\n",
    "X_train_range, X_test_range, y_train_range, y_test_range = train_test_split(X_range, y_range, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model for range prediction\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_range, y_train_range)\n",
    "\n",
    "# Make predictions on the test set for range prediction\n",
    "y_pred_range = regressor.predict(X_test_range)\n",
    "\n",
    "# Split the data into training and testing sets for unstable prediction\n",
    "X_train_unstable, X_test_unstable, y_train_unstable, y_test_unstable = train_test_split(X_unstable, data_unstable['Data_Value_Alt'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier for unstable prediction\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_unstable, y_train_unstable)\n",
    "\n",
    "# Make predictions on the test set for unstable prediction\n",
    "y_pred_unstable = classifier.predict(X_test_unstable)\n",
    "\n",
    "# Print the number of patients within the range\n",
    "print(\"Patients within the range:\", len(data_within_range))\n",
    "\n",
    "# Print the number of unstable estimates\n",
    "print(\"Unstable estimates:\", len(data_unstable))\n",
    "\n",
    "# Classification report for unstable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Replace strings in Confidence_Limit_Low and Confidence_Limit_High with 0\n",
    "data['Confidence_Limit_Low'] = pd.to_numeric(data['Confidence_Limit_Low'], errors='coerce').fillna(0)\n",
    "data['Confidence_Limit_High'] = pd.to_numeric(data['Confidence_Limit_High'], errors='coerce').fillna(0)\n",
    "\n",
    "# Identify category IDs whose Data_Value_Alt is not in the range of confidence levels\n",
    "target_range = [9, 11]  # Specify the range for Data_Value_Alt\n",
    "\n",
    "# Filter out rows where Data_Value_Alt is not within the confidence level range\n",
    "filtered_data = data[(data['Data_Value_Alt'] < target_range[0]) | (data['Data_Value_Alt'] > target_range[1])]\n",
    "\n",
    "# Get the category IDs of the filtered data\n",
    "category_ids = filtered_data['CategoryID']\n",
    "\n",
    "# Create a new DataFrame with the category IDs\n",
    "result_df = pd.DataFrame({'CategoryID': category_ids})\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result_df.to_csv('ans.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal data length 85800\n",
      "83097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "print(f\"orginal data length {len(data)}\")\n",
    "# Replace strings in Confidence_Limit_Low and Confidence_Limit_High with 0\n",
    "data['Confidence_Limit_Low'] = pd.to_numeric(data['Confidence_Limit_Low'], errors='coerce').fillna(0)\n",
    "data['Confidence_Limit_High'] = pd.to_numeric(data['Confidence_Limit_High'], errors='coerce').fillna(0)\n",
    "\n",
    "# Identify rows where Data_Value_Alt is not in the range of confidence levels\n",
    "target_range = [9, 11]  # Specify the range for Data_Value_Alt\n",
    "\n",
    "# Filter out rows where Data_Value_Alt is within the confidence level range\n",
    "filtered_data = data[(data['Data_Value_Alt'] < target_range[0]) | (data['Data_Value_Alt'] > target_range[1])]\n",
    "\n",
    "# Create a new DataFrame with the details and CategoryID\n",
    "result_df = filtered_data[['Year', 'LocationAbbr', 'LocationDesc', 'Datasource', 'Category', 'Topic', 'Indicator', 'Data_Value_Type',\n",
    "                           'Data_Value_Unit', 'Data_Value', 'Data_Value_Alt', 'Data_Value_Footnote_Symbol',\n",
    "                           'Data_Value_Footnote', 'Confidence_Limit_Low', 'Confidence_Limit_High',\n",
    "                           'Break_Out_Category', 'Break_out', 'CategoryID', 'TopicID', 'IndicatorID',\n",
    "                           'Data_Value_TypeID', 'BreakoutCategoryID', 'BreakOutID', 'LocationID', 'GeoLocation']]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result_df.to_csv('ans.csv', index=False)\n",
    "print(len(result_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original data: 85800\n",
      "Accuracy: 1.0\n",
      "Filtered data: 83097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "print(f\"Length of original data: {len(data)}\")\n",
    "# Replace string values in Confidence_Limit_Low and Confidence_Limit_High with 0\n",
    "data['Confidence_Limit_Low'] = pd.to_numeric(data['Confidence_Limit_Low'], errors='coerce').fillna(0)\n",
    "data['Confidence_Limit_High'] = pd.to_numeric(data['Confidence_Limit_High'], errors='coerce').fillna(0)\n",
    "\n",
    "# Prepare the features and target variable\n",
    "features = data[['Confidence_Limit_Low', 'Confidence_Limit_High']]\n",
    "target = ((data['Data_Value_Alt'] >= data['Confidence_Limit_Low']) & (data['Data_Value_Alt'] <= data['Confidence_Limit_High'])).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "target_range=[9,11]\n",
    "# Filter the dataset based on predictions\n",
    "# Filter out rows where Data_Value_Alt is within the confidence level range\n",
    "filtered_data = data[(data['Data_Value_Alt'] < target_range[0]) | (data['Data_Value_Alt'] > target_range[1])]\n",
    "\n",
    "print(f\"Filtered data: {len(filtered_data)}\")\n",
    "# Save the filtered dataset as a new CSV file\n",
    "filtered_data.to_csv('filtered_dataset.csv', index=False)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Assuming you have a trained model named \"model\"\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
